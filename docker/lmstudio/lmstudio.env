# LM Studio Configuration for Agent Zero
# Copy this file to .env in your Agent Zero root directory

# LM Studio API Configuration
LM_STUDIO_BASE_URL=http://lmstudio:1234/v1
API_KEY_LMSTUDIO=none

# Model Configuration for Agent Zero
# Chat Model (Main conversation model)
CHAT_MODEL_PROVIDER=LMSTUDIO
CHAT_MODEL_NAME=llama-3.1-8b-instruct
CHAT_MODEL_CTX_LENGTH=32768
CHAT_MODEL_VISION=false
CHAT_MODEL_TEMPERATURE=0.7

# Utility Model (For internal tasks)
UTIL_MODEL_PROVIDER=LMSTUDIO
UTIL_MODEL_NAME=llama-3.1-8b-instruct
UTIL_MODEL_CTX_LENGTH=32768
UTIL_MODEL_TEMPERATURE=0.3

# Embedding Model (For knowledge and memory)
EMBED_MODEL_PROVIDER=LMSTUDIO
EMBED_MODEL_NAME=nomic-embed-text-v1.5
EMBED_MODEL_CTX_LENGTH=8192

# Browser Model (For web browsing tasks)
BROWSER_MODEL_PROVIDER=LMSTUDIO
BROWSER_MODEL_NAME=llama-3.1-8b-instruct
BROWSER_MODEL_VISION=false
BROWSER_MODEL_TEMPERATURE=0.5

# Performance Settings
CHAT_MODEL_RL_REQUESTS=0
CHAT_MODEL_RL_INPUT=0
CHAT_MODEL_RL_OUTPUT=0
UTIL_MODEL_RL_REQUESTS=0
UTIL_MODEL_RL_INPUT=0
UTIL_MODEL_RL_OUTPUT=0
EMBED_MODEL_RL_REQUESTS=0
EMBED_MODEL_RL_INPUT=0

# Agent Configuration
AGENT_PROMPTS_SUBDIR=default
AGENT_MEMORY_SUBDIR=default
AGENT_KNOWLEDGE_SUBDIR=custom

# Web UI Configuration
WEB_UI_PORT=50080
USE_CLOUDFLARE=false

# Docker Configuration
CODE_EXEC_DOCKER_ENABLED=false
CODE_EXEC_SSH_ENABLED=true

# Other Settings
TOKENIZERS_PARALLELISM=true
PYDEVD_DISABLE_FILE_VALIDATION=1

# MCP Configuration
MCP_SERVERS={"mcpServers": {}}
MCP_CLIENT_INIT_TIMEOUT=5
MCP_CLIENT_TOOL_TIMEOUT=120
MCP_SERVER_ENABLED=false

# Speech-to-Text Configuration
STT_MODEL_SIZE=base
STT_LANGUAGE=en
STT_SILENCE_THRESHOLD=0.3
STT_SILENCE_DURATION=1000
STT_WAITING_TIMEOUT=2000

# Remote Access Configuration
RFC_AUTO_DOCKER=true
RFC_URL=localhost
RFC_PORT_HTTP=55080
RFC_PORT_SSH=55022
